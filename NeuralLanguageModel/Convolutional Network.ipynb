{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络笔记\n",
    "\n",
    "假设我们有一个句子，其中有 $l$ 个term，每个term都有$d$维特征。\n",
    "\n",
    "我们尝试使用卷积神经网+maxpooling来为其提取上下文相关的特征。\n",
    "\n",
    "## 卷积模型\n",
    "\n",
    "根据theano中的实现，conv2d用来实现卷积:\n",
    "\n",
    "* 输入是一个4维 tensor，其维度信息为：\n",
    "    [mini-batch size, number of input feature maps, image height, image width]\n",
    "* 卷积核是一个 4维 tensor，其维度信息为：\n",
    "    [number of feature maps at layer m, number of feature maps at layer m-1, filter height, filter width]\n",
    "    \n",
    "在NLP任务中，我们的问题是字符序列。但是每个字符有一个特征向量。故，对一个句子，我们还是得到一个特征矩阵。我们需要对这个特征矩阵，使用conv2d，沿着字符序列方向做卷积，即其卷积宽度=特征维度。\n",
    "\n",
    "故，对NLP任务，假设我们的特征矩阵，是term为行，feature 为列存储的，那么conv2d的设置为：\n",
    "\n",
    "* 输入是一个4维 tensor，其维度信息为：\n",
    "    [mini-batch size, 1, $l$, $d$]\n",
    "* 卷积核是一个 4维 tensor，其维度信息为：\n",
    "    [number of feature maps at layer m, 1, filter height, $d$]\n",
    "    \n",
    "该设置下，卷积层的输出维度为：\n",
    "\n",
    "* [mini-batch size， number of feature maps at layer m, $l$ - filter_height + 1, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.tensor.nnet import conv\n",
    "\n",
    "import numpy\n",
    "\n",
    "rng = numpy.random.RandomState(23455)\n",
    "\n",
    "l = 25\n",
    "d = 100\n",
    "\n",
    "batch_size = 5\n",
    "feature = theano.shared(numpy.asarray(\n",
    "            rng.uniform(low=-.5, high=.5, size=(batch_size,1,l, d)),\n",
    "            dtype='float'), name ='feature')\n",
    " \n",
    "output_feature_dim = 50\n",
    "window_height = 3\n",
    "w_shp = (output_feature_dim, 1, window_height, d)\n",
    "w_bound = numpy.sqrt(1 * window_height * d)\n",
    "W = theano.shared( numpy.asarray(\n",
    "            rng.uniform(\n",
    "                low=-1.0 / w_bound,\n",
    "                high=1.0 / w_bound,\n",
    "                size=w_shp),\n",
    "            dtype='float'), name ='W')\n",
    "b_shp = (output_feature_dim,)\n",
    "b = theano.shared(numpy.asarray(\n",
    "            rng.uniform(low=-.5, high=.5, size=b_shp),\n",
    "            dtype='float'), name ='b')\n",
    "\n",
    "conv_out = conv.conv2d(feature, W)\n",
    "\n",
    "conv_trans_out = T.nnet.sigmoid(conv_out + b.dimshuffle('x', 0, 'x', 'x'))\n",
    "\n",
    "assert max(abs((conv_trans_out.shape.eval() - numpy.array([ batch_size,  output_feature_dim, l - window_height + 1,  1])))) == 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling\n",
    "\n",
    "经过卷积，我们获得了term之间彼此相关信息的特征。但是该特征的维度，是与句子的长度相关的，给后续网络学习带来不便。\n",
    "\n",
    "处理这一问题的一个方案叫做max-pooling。其之前用于在图像处理中，对图像进行的非线性降采样。max-pooling将图像划分为不相交的小块，然后输出每个小块的最大值。对于图像处理，它可以减少后续步骤的计算量，而且可以带来额外的抵抗旋转影响的鲁棒性。\n",
    "\n",
    "对于NLP任务，max-pooling 的主要目的是将卷积步骤获得的大小不一的局部特征向量，转化成为固定维度的全局特征向量。为了确保输出固定维度特征的向量，需要对term 维度进行reduce操作，以消除term数量变化的影响。为保证保留重要信息，采用max操作。\n",
    "\n",
    "在上面的设定中，即对卷积层输出的第三个维度进行max操作。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_pool_output =  T.max(conv_trans_out, axis=2)\n",
    "output_feature = max_pool_output.reshape((batch_size,  -1))\n",
    "\n",
    "assert max(abs((output_feature.shape.eval() - numpy.array([ batch_size,  output_feature_dim])))) == 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
